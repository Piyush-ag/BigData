{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f1ed26b0",
      "metadata": {},
      "source": [
        "# Abstract for model\n",
        "\n",
        "## Dataset and Approach\n",
        "- The **IMDB Movie Reviews Dataset** from **Kaggle** has been used for sentiment analysis.\n",
        "- The dataset contains **50,000 reviews**, evenly split between **positive** and **negative** sentiments.\n",
        "- Preprocessing includes:\n",
        "  - **Text Tokenization**: Breaking reviews into individual words.\n",
        "  - **Feature Engineering**: Using **HashingTF** to convert text into numerical features.\n",
        "  - **Classification Model**: **Logistic Regression** is trained to classify reviews as **positive (1)** or **negative (0)**.\n",
        "\n",
        "---\n",
        "\n",
        "## Model Performance Summary\n",
        "\n",
        "- **Accuracy (90.90%)**: The model correctly classifies **90.90%** of the reviews.\n",
        "- **Precision (83.06%)**: When the model predicts **positive**, it’s correct **83.06%** of the time.  \n",
        "  - However, **849 negative reviews were misclassified as positive** (**False Positives**).\n",
        "- **Recall (85.67%)**: The model correctly identifies **85.67%** of all actual **positive reviews**.  \n",
        "  - **696 positive reviews were misclassified as negative** (**False Negatives**).\n",
        "- **F1-Score (84.34%)**: The harmonic mean of **precision and recall**, indicating a **balanced overall performance**.\n",
        "\n",
        "---\n",
        "\n",
        "## Insights and Improvement Areas\n",
        "\n",
        "✅ **Strengths:**\n",
        "- High accuracy (**90.90%**) suggests a well-trained model.\n",
        "- Balanced **precision-recall tradeoff**, preventing extreme biases.\n",
        "- Effective in capturing sentiment from text using simple **TF-based features**.\n",
        "\n",
        "⚠ **Areas for Improvement:**\n",
        "- **Reduce False Positives (FP)**: Some negative reviews are incorrectly predicted as positive.\n",
        "- **Reduce False Negatives (FN)**: Some positive reviews are being classified as negative.\n",
        "- **Potential Enhancements:**\n",
        "  - Use **TF-IDF** instead of HashingTF to improve feature representation.\n",
        "  - Try more complex models like **Random Forest** or **Deep Learning (BERT)**.\n",
        "  - Fine-tune **Logistic Regression** parameters to optimize classification.\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "The model provides **strong sentiment classification (90.90% accuracy)** but can be improved by enhancing **feature extraction techniques** and **model tuning**. Future enhancements could involve **advanced NLP techniques** to boost precision and recall.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebcfa9cd",
      "metadata": {
        "id": "ebcfa9cd"
      },
      "outputs": [],
      "source": [
        "# Step 1: Initialize Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import Tokenizer, HashingTF\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col, expr, when\n",
        "import pandas as pd\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SentimentAnalysis\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d1658c66",
      "metadata": {
        "id": "d1658c66"
      },
      "outputs": [],
      "source": [
        "# Step 2: Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/IMDB Dataset.csv\")\n",
        "data = spark.createDataFrame(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "DyWH_4ENj8ps",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DyWH_4ENj8ps",
        "outputId": "613c3505-c47d-4bad-d27c-38b28763196b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e715c78d",
      "metadata": {
        "id": "e715c78d"
      },
      "outputs": [],
      "source": [
        "# Step 3: Preprocessing - Map sentiments to numeric labels\n",
        "data = data.withColumn(\"label\", (data[\"sentiment\"] == \"positive\").cast(\"int\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "79f9357a",
      "metadata": {
        "id": "79f9357a"
      },
      "outputs": [],
      "source": [
        "# Step 4: Create an ML pipeline\n",
        "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"words\")  # Tokenize text\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"features\")  # Convert words to feature vectors\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")  # Logistic regression model\n",
        "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e046fecd",
      "metadata": {
        "id": "e046fecd"
      },
      "outputs": [],
      "source": [
        "# Step 5: Split data into training and testing sets\n",
        "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "364d9edc",
      "metadata": {
        "id": "364d9edc"
      },
      "outputs": [],
      "source": [
        "# Step 6: Train the model\n",
        "model = pipeline.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "3eb7dfcd",
      "metadata": {
        "id": "3eb7dfcd"
      },
      "outputs": [],
      "source": [
        "# Step 7: Make predictions on the test set\n",
        "predictions = model.transform(testData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bbdda6e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bbdda6e1",
        "outputId": "ba6de966-4c0c-4214-e11c-28e90aaeec5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9090484649150764\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Evaluate the model\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7cda5edc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7cda5edc",
        "outputId": "8d832ed9-751b-4eb5-efcf-dc5d952f3711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----+\n",
            "|confusion|count|\n",
            "+---------+-----+\n",
            "|       TP| 4162|\n",
            "|       TN| 4156|\n",
            "|       FN|  696|\n",
            "|       FP|  849|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 9: Confusion Matrix\n",
        "confusion_matrix = predictions.withColumn(\n",
        "    \"confusion\",\n",
        "    when((col(\"label\") == 1) & (col(\"prediction\") == 1), \"TP\")\n",
        "    .when((col(\"label\") == 0) & (col(\"prediction\") == 0), \"TN\")\n",
        "    .when((col(\"label\") == 1) & (col(\"prediction\") == 0), \"FN\")\n",
        "    .when((col(\"label\") == 0) & (col(\"prediction\") == 1), \"FP\")\n",
        ")\n",
        "\n",
        "confusion_counts = confusion_matrix.groupBy(\"confusion\").count()\n",
        "confusion_counts.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ad35740b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ad35740b",
        "outputId": "a89a9645-4e96-4f51-9fdf-ff38e1275396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.8305727399720615\n",
            "Recall: 0.8567311650885138\n",
            "F1-Score: 0.8434491843145202\n"
          ]
        }
      ],
      "source": [
        "# Step 10: Calculate Precision, Recall, and F1-Score\n",
        "TP = confusion_matrix.filter(col(\"confusion\") == \"TP\").count()\n",
        "TN = confusion_matrix.filter(col(\"confusion\") == \"TN\").count()\n",
        "FP = confusion_matrix.filter(col(\"confusion\") == \"FP\").count()\n",
        "FN = confusion_matrix.filter(col(\"confusion\") == \"FN\").count()\n",
        "\n",
        "precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
        "recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
        "f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "e2aa5f0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "e2aa5f0d",
        "outputId": "81b5deeb-c624-4798-fc7c-1a2b0c78c0c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Misclassified Examples:\n",
            "+----------------------------------------------------------------------------------------------------+-----+----------+\n",
            "|truncated_review                                                                                    |label|prediction|\n",
            "+----------------------------------------------------------------------------------------------------+-----+----------+\n",
            "|!!!! POSSIBLE MILD SPOILER !!!!!<br /><br />As I watched the first half of GUILTY AS SIN I couldn`t |0    |1.0       |\n",
            "|\"... the beat is too strong ... we're deaf mutants now--like them\", Rex Voorhas Ormine<br /><br />I |1    |0.0       |\n",
            "|\"Bell Book and Candle\" was shown recently on cable. Not having seen it for a while, we decided to ta|1    |0.0       |\n",
            "|\"Die Sieger\" was highly recommended to be one of the few good action movies made in Germany. I watch|0    |1.0       |\n",
            "|\"I thought I'd be locked away in a padded cell and they'd throw away the key\" (Thus is a paraphrased|0    |1.0       |\n",
            "|\"Nada\" was the most inadequate follow-up to \"Les NOces Rouges\" which,with hindsight,appears now as t|0    |1.0       |\n",
            "|\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell |0    |1.0       |\n",
            "|\"The Man Who Knew Too Much\" falls into that Hitchcock middle ground that characterized many of his f|1    |0.0       |\n",
            "|\"True\" story of a late monster that appears when an American industrial plant begins polluting the w|0    |1.0       |\n",
            "|\"Two Hands\" is a hilarious Australian gangster movie set in really sultry Sydney. I bet tourists nev|1    |0.0       |\n",
            "+----------------------------------------------------------------------------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 11: Analyze Misclassified Examples\n",
        "print(\"Misclassified Examples:\")\n",
        "misclassified = predictions.filter(col(\"label\") != col(\"prediction\"))\n",
        "misclassified.select(\n",
        "    col(\"review\").substr(1, 100).alias(\"truncated_review\"),\n",
        "    \"label\",\n",
        "    \"prediction\"\n",
        ").show(10, truncate=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
